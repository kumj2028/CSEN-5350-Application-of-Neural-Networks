{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 8\n",
    "## Mengxiang Jiang\n",
    "\n",
    "The majority of the code here comes from the [Companion Jupyter notebooks for the book \"Deep Learning with Python\"](https://github.com/fchollet/deep-learning-with-python-notebooks) by FranÃ§ois Chollet, specifically chapter 8.\n",
    "If the code comes from somewhere else it will have a source linked to the original.\\\n",
    "[Video Link](https://youtu.be/5QYS399Eoio)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1: Introduction to convnets\n",
    "**Instantiating a small convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 17:07:53.471611: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 17:07:53.542322: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-03-28 17:07:54.341503: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.343182: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.343260: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.343543: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-28 17:07:54.344169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.344241: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.344284: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.651824: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.651926: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.651977: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-03-28 17:07:54.652030: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 7760 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3080, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.MaxPooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying the model's summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 5, 5, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 1152)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the convnet on MNIST images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-28 17:07:55.790058: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8100\n",
      "2023-03-28 17:07:56.613665: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-03-28 17:07:56.615195: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7f3407b66b00 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-28 17:07:56.615208: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-03-28 17:07:56.617485: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-03-28 17:07:56.672345: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657/657 [==============================] - 3s 2ms/step - loss: 0.2016 - accuracy: 0.9382 - val_loss: 0.1755 - val_accuracy: 0.9410\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0540 - accuracy: 0.9835 - val_loss: 0.0659 - val_accuracy: 0.9816\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0376 - accuracy: 0.9885 - val_loss: 0.0475 - val_accuracy: 0.9867\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0280 - accuracy: 0.9908 - val_loss: 0.0429 - val_accuracy: 0.9881\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0202 - accuracy: 0.9937 - val_loss: 0.0423 - val_accuracy: 0.9880\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f38880b86d0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating the convnet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 865us/step - loss: 0.0327 - accuracy: 0.9903\n",
      "Test accuracy: 0.990\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2: Add Stride=2 to Conv2D layers and remove MaxPooling2D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\", strides=2)(inputs)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", strides=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model2 = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 13, 13, 32)        320       \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 6, 6, 64)          18496     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2048)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                20490     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 113,162\n",
      "Trainable params: 113,162\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9350 - val_loss: 0.0959 - val_accuracy: 0.9702\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0568 - val_accuracy: 0.9826\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0395 - accuracy: 0.9877 - val_loss: 0.0578 - val_accuracy: 0.9830\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.0480 - val_accuracy: 0.9861\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0204 - accuracy: 0.9939 - val_loss: 0.0484 - val_accuracy: 0.9868\n",
      "313/313 [==============================] - 0s 889us/step - loss: 0.0372 - accuracy: 0.9884\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "model2.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "model2.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.3)\n",
    "\n",
    "test_loss, test_acc = model2.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentary**\n",
    "\n",
    "The test accuracy of removing the max pooling layers and changing the non-strided convolution layers to strided ones is slightly worse than before. This might be because using strided convolution is looking at sparse windows of the inputs which could miss feature-presence information, while max pooling keeps the maximal activation of the dense windows and therefore doesn't miss the information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3: Replacing Max Pooling with Average Pooling"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.AveragePooling2D(pool_size=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model3 = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 13, 13, 32)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 5, 5, 64)         0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 104,202\n",
      "Trainable params: 104,202\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.2509 - accuracy: 0.9254 - val_loss: 0.1038 - val_accuracy: 0.9688\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0689 - accuracy: 0.9794 - val_loss: 0.0717 - val_accuracy: 0.9791\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0465 - accuracy: 0.9851 - val_loss: 0.0574 - val_accuracy: 0.9839\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0351 - accuracy: 0.9891 - val_loss: 0.0495 - val_accuracy: 0.9862\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0278 - accuracy: 0.9912 - val_loss: 0.0510 - val_accuracy: 0.9859\n",
      "313/313 [==============================] - 0s 843us/step - loss: 0.0397 - accuracy: 0.9861\n",
      "Test accuracy: 0.986\n"
     ]
    }
   ],
   "source": [
    "model3.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "model3.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.3)\n",
    "\n",
    "test_loss, test_acc = model3.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentary**\n",
    "\n",
    "The test accuracy of the average pooling is slightly worse than using max pooling. This might be because using average activation over the maximal activation could dilute the feature-presence information."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4: Replacing Max Pooling with Strided Conv2D Layers"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
    "x = layers.Conv2D(filters=32, kernel_size=2, activation=\"relu\", strides=2)(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Conv2D(filters=64, kernel_size=2, activation=\"relu\", strides=2)(x)\n",
    "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(x)\n",
    "model4 = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 13, 13, 32)        4128      \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 5, 5, 64)          16448     \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 1152)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                11530     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,778\n",
      "Trainable params: 124,778\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and Evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "657/657 [==============================] - 2s 2ms/step - loss: 0.2058 - accuracy: 0.9347 - val_loss: 0.0797 - val_accuracy: 0.9755\n",
      "Epoch 2/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0586 - accuracy: 0.9815 - val_loss: 0.0559 - val_accuracy: 0.9811\n",
      "Epoch 3/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0380 - accuracy: 0.9882 - val_loss: 0.0541 - val_accuracy: 0.9848\n",
      "Epoch 4/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0276 - accuracy: 0.9916 - val_loss: 0.0614 - val_accuracy: 0.9847\n",
      "Epoch 5/5\n",
      "657/657 [==============================] - 1s 2ms/step - loss: 0.0210 - accuracy: 0.9935 - val_loss: 0.0476 - val_accuracy: 0.9867\n",
      "313/313 [==============================] - 0s 928us/step - loss: 0.0380 - accuracy: 0.9883\n",
      "Test accuracy: 0.988\n"
     ]
    }
   ],
   "source": [
    "model4.compile(optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "model4.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.3)\n",
    "\n",
    "test_loss, test_acc = model4.evaluate(test_images, test_labels)\n",
    "print(f\"Test accuracy: {test_acc:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentary**\n",
    "\n",
    "The test accuracy of strided convolution layers replacing max pooling layers is slightly worse than the original. This might be because the additional parameters of the strided convolution layers made the model overfit more quickly, as evidenced by the lower training loss than the original but higher validation and test loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
