{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 12\n",
    "## Mengxiang Jiang\n",
    "\n",
    "The majority of the code here comes from the [Companion Jupyter notebooks for the book \"Deep Learning with Python\"](https://github.com/fchollet/deep-learning-with-python-notebooks) by Fran√ßois Chollet, specifically chapter 11.\n",
    "If the code comes from somewhere else it will have a source linked to the original.\\\n",
    "[Video Link](https://youtu.be/eznAqvv8PaI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the IMDB movie reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 80.2M  100 80.2M    0     0  26.2M      0  0:00:03  0:00:03 --:--:-- 26.3M\n",
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "!tar -xf aclImdb_v1.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!rm -r aclImdb/train/unsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "I first saw this back in the early 90s on UK TV, i did like it then but i missed the chance to tape it, many years passed but the film always stuck with me and i lost hope of seeing it TV again, the main thing that stuck with me was the end, the hole castle part really touched me, its easy to watch, has a great story, great music, the list goes on and on, its OK me saying how good it is but everyone will take there own best bits away with them once they have seen it, yes the animation is top notch and beautiful to watch, it does show its age in a very few parts but that has now become part of it beauty, i am so glad it has came out on DVD as it is one of my top 10 films of all time. Buy it or rent it just see it, best viewing is at night alone with drink and food in reach so you don't have to stop the film.<br /><br />Enjoy"
     ]
    }
   ],
   "source": [
    "!cat aclImdb/train/pos/4077_10.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pathlib, shutil, random\n",
    "\n",
    "base_dir = pathlib.Path(\"aclImdb\")\n",
    "val_dir = base_dir / \"val\"\n",
    "train_dir = base_dir / \"train\"\n",
    "for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1337).shuffle(files)\n",
    "    num_val_samples = int(0.2 * len(files))\n",
    "    val_files = files[-num_val_samples:]\n",
    "    for fname in val_files:\n",
    "        shutil.move(train_dir / category / fname,\n",
    "                    val_dir / category / fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 files belonging to 2 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "batch_size = 32\n",
    "\n",
    "train_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/train\", batch_size=batch_size\n",
    ")\n",
    "val_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/val\", batch_size=batch_size\n",
    ")\n",
    "test_ds = keras.utils.text_dataset_from_directory(\n",
    "    \"aclImdb/test\", batch_size=batch_size\n",
    ")\n",
    "text_only_train_ds = train_ds.map(lambda x, y: x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Displaying the shapes and dtypes of the first batch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'One night I was waiting for my friends to come back to the apt and \"Gymkata\" happened to be on; I watched way too much of it. It is indeed hilarious, and horrifying, really. Think about it this way--if in your job you had an idea for something this bad and went on to execute it in as terrible a fashion as this, how long exactly would you last? Not as long as this movie. It\\'s a must-see, obviously.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds:\n",
    "    print(\"inputs.shape:\", inputs.shape)\n",
    "    print(\"inputs.dtype:\", inputs.dtype)\n",
    "    print(\"targets.shape:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\", inputs[0])\n",
    "    print(\"targets[0]:\", targets[0])\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorizing the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "max_length = 600\n",
    "max_tokens = 20000\n",
    "text_vectorization = layers.TextVectorization(\n",
    "    max_tokens=max_tokens,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=max_length,\n",
    ")\n",
    "text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "int_train_ds = train_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "int_val_ds = val_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)\n",
    "int_test_ds = test_ds.map(\n",
    "    lambda x, y: (text_vectorization(x), y),\n",
    "    num_parallel_calls=4)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transformer encoder implemented as a subclassed `Layer`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class TransformerEncoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "\n",
    "    def call(self, inputs, mask=None):\n",
    "        if mask is not None:\n",
    "            mask = mask[:, tf.newaxis, :]\n",
    "        attention_output = self.attention(\n",
    "            inputs, inputs, attention_mask=mask)\n",
    "        proj_input = self.layernorm_1(inputs + attention_output)\n",
    "        proj_output = self.dense_proj(proj_input)\n",
    "        return self.layernorm_2(proj_input + proj_output)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Using the Transformer encoder for text classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, None)]            0         \n",
      "                                                                 \n",
      " embedding (Embedding)       (None, None, 256)         5120000   \n",
      "                                                                 \n",
      " transformer_encoder (Transf  (None, None, 256)        543776    \n",
      " ormerEncoder)                                                   \n",
      "                                                                 \n",
      " global_max_pooling1d (Globa  (None, 256)              0         \n",
      " lMaxPooling1D)                                                  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 256)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,664,033\n",
      "Trainable params: 5,664,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 20000\n",
    "embed_dim = 256\n",
    "num_heads = 2\n",
    "dense_dim = 32\n",
    "\n",
    "inputs = keras.Input(shape=(None,), dtype=\"int64\")\n",
    "x = layers.Embedding(vocab_size, embed_dim)(inputs)\n",
    "x = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.compile(optimizer=\"rmsprop\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training and evaluating the Transformer encoder based model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:00:42.679389: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-04-24 16:00:43.076519: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8200\n",
      "2023-04-24 16:00:43.470759: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x7fee34004160 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-04-24 16:00:43.470775: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): NVIDIA GeForce RTX 3080, Compute Capability 8.6\n",
      "2023-04-24 16:00:43.472846: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-04-24 16:00:43.530652: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 34s 51ms/step - loss: 0.4914 - accuracy: 0.7700 - val_loss: 0.3888 - val_accuracy: 0.8248\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 19s 31ms/step - loss: 0.3431 - accuracy: 0.8486 - val_loss: 0.3114 - val_accuracy: 0.8696\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 16s 26ms/step - loss: 0.3090 - accuracy: 0.8691 - val_loss: 0.3036 - val_accuracy: 0.8756\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 14s 22ms/step - loss: 0.2770 - accuracy: 0.8839 - val_loss: 0.2908 - val_accuracy: 0.8792\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 14s 22ms/step - loss: 0.2469 - accuracy: 0.8983 - val_loss: 0.3246 - val_accuracy: 0.8640\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 13s 20ms/step - loss: 0.2122 - accuracy: 0.9168 - val_loss: 0.2877 - val_accuracy: 0.8840\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 12s 20ms/step - loss: 0.1814 - accuracy: 0.9300 - val_loss: 0.3030 - val_accuracy: 0.8836\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 12s 20ms/step - loss: 0.1549 - accuracy: 0.9412 - val_loss: 0.3202 - val_accuracy: 0.8788\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.1293 - accuracy: 0.9534 - val_loss: 0.3268 - val_accuracy: 0.8770\n",
      "Epoch 10/20\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.1069 - accuracy: 0.9612 - val_loss: 0.3430 - val_accuracy: 0.8830\n",
      "Epoch 11/20\n",
      "625/625 [==============================] - 12s 19ms/step - loss: 0.0823 - accuracy: 0.9704 - val_loss: 0.4823 - val_accuracy: 0.8522\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3054 - accuracy: 0.8735\n",
      "Test acc: 0.873\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"transformer_encoder.keras\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "encoder_history = model.fit(int_train_ds, validation_data=int_val_ds, epochs=20, callbacks=callbacks)\n",
    "model = keras.models.load_model(\n",
    "    \"transformer_encoder.keras\",\n",
    "    custom_objects={\"TransformerEncoder\": TransformerEncoder})\n",
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3054 - accuracy: 0.8735\n",
      "Test acc: 0.873\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test acc: {model.evaluate(int_test_ds)[1]:.3f}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beyond text classification: Sequence-to-sequence learning\n",
    "### A machine translation example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n",
      "--2023-04-24 16:04:58--  http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
      "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.16.128, 142.251.111.128, 142.251.163.128, ...\n",
      "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.16.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 2638744 (2.5M) [application/zip]\n",
      "Saving to: ‚Äòspa-eng.zip‚Äô\n",
      "\n",
      "spa-eng.zip         100%[===================>]   2.52M  4.26MB/s    in 0.6s    \n",
      "\n",
      "2023-04-24 16:04:59 (4.26 MB/s) - ‚Äòspa-eng.zip‚Äô saved [2638744/2638744]\n",
      "\n",
      "/bin/bash: /home/habib/miniconda3/envs/tf-py38/lib/libtinfo.so.6: no version information available (required by /bin/bash)\n"
     ]
    }
   ],
   "source": [
    "!wget http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n",
    "!unzip -q spa-eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = \"spa-eng/spa.txt\"\n",
    "with open(text_file) as f:\n",
    "    lines = f.read().split(\"\\n\")[:-1]\n",
    "text_pairs = []\n",
    "for line in lines:\n",
    "    english, spanish = line.split(\"\\t\")\n",
    "    spanish = \"[start] \" + spanish + \" [end]\"\n",
    "    text_pairs.append((english, spanish))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('I am happiest when I am reading.', '[start] Soy el m√°s feliz cuando leo. [end]')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(random.choice(text_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.shuffle(text_pairs)\n",
    "num_val_samples = int(0.15 * len(text_pairs))\n",
    "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
    "train_pairs = text_pairs[:num_train_samples]\n",
    "val_pairs = text_pairs[num_train_samples:num_train_samples + num_val_samples]\n",
    "test_pairs = text_pairs[num_train_samples + num_val_samples:]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vectorizing the English and Spanish text pairs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "strip_chars = string.punctuation + \"¬ø\"\n",
    "strip_chars = strip_chars.replace(\"[\", \"\")\n",
    "strip_chars = strip_chars.replace(\"]\", \"\")\n",
    "\n",
    "def custom_standardization(input_string):\n",
    "    lowercase = tf.strings.lower(input_string)\n",
    "    return tf.strings.regex_replace(\n",
    "        lowercase, f\"[{re.escape(strip_chars)}]\", \"\")\n",
    "\n",
    "vocab_size = 15000\n",
    "sequence_length = 20\n",
    "\n",
    "source_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length,\n",
    ")\n",
    "target_vectorization = layers.TextVectorization(\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=sequence_length + 1,\n",
    "    standardize=custom_standardization,\n",
    ")\n",
    "train_english_texts = [pair[0] for pair in train_pairs]\n",
    "train_spanish_texts = [pair[1] for pair in train_pairs]\n",
    "source_vectorization.adapt(train_english_texts)\n",
    "target_vectorization.adapt(train_spanish_texts)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Preparing datasets for the translation task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "def format_dataset(eng, spa):\n",
    "    eng = source_vectorization(eng)\n",
    "    spa = target_vectorization(spa)\n",
    "    return ({\n",
    "        \"english\": eng,\n",
    "        \"spanish\": spa[:, :-1],\n",
    "    }, spa[:, 1:])\n",
    "\n",
    "def make_dataset(pairs):\n",
    "    eng_texts, spa_texts = zip(*pairs)\n",
    "    eng_texts = list(eng_texts)\n",
    "    spa_texts = list(spa_texts)\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((eng_texts, spa_texts))\n",
    "    dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.map(format_dataset, num_parallel_calls=4)\n",
    "    return dataset.shuffle(2048).prefetch(16).cache()\n",
    "\n",
    "train_ds = make_dataset(train_pairs)\n",
    "val_ds = make_dataset(val_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs['english'].shape: (64, 20)\n",
      "inputs['spanish'].shape: (64, 20)\n",
      "targets.shape: (64, 20)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-24 16:07:38.417465: W tensorflow/core/kernels/data/cache_dataset_ops.cc:856] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_ds.take(1):\n",
    "    print(f\"inputs['english'].shape: {inputs['english'].shape}\")\n",
    "    print(f\"inputs['spanish'].shape: {inputs['spanish'].shape}\")\n",
    "    print(f\"targets.shape: {targets.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence-to-sequence learning with Transformer\n",
    "#### The Transformer decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(layers.Layer):\n",
    "    def __init__(self, embed_dim, dense_dim, num_heads, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.embed_dim = embed_dim\n",
    "        self.dense_dim = dense_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.attention_1 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.attention_2 = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.dense_proj = keras.Sequential(\n",
    "            [layers.Dense(dense_dim, activation=\"relu\"),\n",
    "             layers.Dense(embed_dim),]\n",
    "        )\n",
    "        self.layernorm_1 = layers.LayerNormalization()\n",
    "        self.layernorm_2 = layers.LayerNormalization()\n",
    "        self.layernorm_3 = layers.LayerNormalization()\n",
    "        self.supports_masking = True\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config.update({\n",
    "            \"embed_dim\": self.embed_dim,\n",
    "            \"num_heads\": self.num_heads,\n",
    "            \"dense_dim\": self.dense_dim,\n",
    "        })\n",
    "        return config\n",
    "\n",
    "    def get_causal_attention_mask(self, inputs):\n",
    "        input_shape = tf.shape(inputs)\n",
    "        batch_size, sequence_length = input_shape[0], input_shape[1]\n",
    "        i = tf.range(sequence_length)[:, tf.newaxis]\n",
    "        j = tf.range(sequence_length)\n",
    "        mask = tf.cast(i >= j, dtype=\"int32\")\n",
    "        mask = tf.reshape(mask, (1, input_shape[1], input_shape[1]))\n",
    "        mult = tf.concat(\n",
    "            [tf.expand_dims(batch_size, -1),\n",
    "             tf.constant([1, 1], dtype=tf.int32)], axis=0)\n",
    "        return tf.tile(mask, mult)\n",
    "\n",
    "    def call(self, inputs, encoder_outputs, mask=None):\n",
    "        causal_mask = self.get_causal_attention_mask(inputs)\n",
    "        if mask is not None:\n",
    "            padding_mask = tf.cast(\n",
    "                mask[:, tf.newaxis, :], dtype=\"int32\")\n",
    "            padding_mask = tf.minimum(padding_mask, causal_mask)\n",
    "        else:\n",
    "            padding_mask = mask\n",
    "        attention_output_1 = self.attention_1(\n",
    "            query=inputs,\n",
    "            value=inputs,\n",
    "            key=inputs,\n",
    "            attention_mask=causal_mask)\n",
    "        attention_output_1 = self.layernorm_1(inputs + attention_output_1)\n",
    "        attention_output_2 = self.attention_2(\n",
    "            query=attention_output_1,\n",
    "            value=encoder_outputs,\n",
    "            key=encoder_outputs,\n",
    "            attention_mask=padding_mask,\n",
    "        )\n",
    "        attention_output_2 = self.layernorm_2(\n",
    "            attention_output_1 + attention_output_2)\n",
    "        proj_output = self.dense_proj(attention_output_2)\n",
    "        return self.layernorm_3(attention_output_2 + proj_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Putting it all together: A Transformer for machine translation\n",
    "**PositionalEmbedding layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEmbedding(layers.Layer):\n",
    "    def __init__(self, sequence_length, input_dim, output_dim, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.token_embeddings = layers.Embedding(\n",
    "            input_dim=input_dim, output_dim=output_dim)\n",
    "        self.position_embeddings = layers.Embedding(\n",
    "            input_dim=sequence_length, output_dim=output_dim)\n",
    "        self.sequence_length = sequence_length\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "\n",
    "    def call(self, inputs):\n",
    "        length = tf.shape(inputs)[-1]\n",
    "        positions = tf.range(start=0, limit=length, delta=1)\n",
    "        embedded_tokens = self.token_embeddings(inputs)\n",
    "        embedded_positions = self.position_embeddings(positions)\n",
    "        return embedded_tokens + embedded_positions\n",
    "\n",
    "    def compute_mask(self, inputs, mask=None):\n",
    "        return tf.math.not_equal(inputs, 0)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(PositionalEmbedding, self).get_config()\n",
    "        config.update({\n",
    "            \"output_dim\": self.output_dim,\n",
    "            \"sequence_length\": self.sequence_length,\n",
    "            \"input_dim\": self.input_dim,\n",
    "        })\n",
    "        return config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**End-to-end Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 256\n",
    "dense_dim = 2048\n",
    "num_heads = 8\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"english\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(encoder_inputs)\n",
    "encoder_outputs = TransformerEncoder(embed_dim, dense_dim, num_heads)(x)\n",
    "\n",
    "decoder_inputs = keras.Input(shape=(None,), dtype=\"int64\", name=\"spanish\")\n",
    "x = PositionalEmbedding(sequence_length, vocab_size, embed_dim)(decoder_inputs)\n",
    "x = TransformerDecoder(embed_dim, dense_dim, num_heads)(x, encoder_outputs)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "decoder_outputs = layers.Dense(vocab_size, activation=\"softmax\")(x)\n",
    "transformer = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training the sequence-to-sequence Transformer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1302/1302 [==============================] - 37s 26ms/step - loss: 3.8069 - accuracy: 0.4384 - val_loss: 2.8890 - val_accuracy: 0.5335\n",
      "Epoch 2/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.8638 - accuracy: 0.5488 - val_loss: 2.5459 - val_accuracy: 0.5847\n",
      "Epoch 3/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.5643 - accuracy: 0.5932 - val_loss: 2.4513 - val_accuracy: 0.6009\n",
      "Epoch 4/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.3988 - accuracy: 0.6193 - val_loss: 2.3318 - val_accuracy: 0.6245\n",
      "Epoch 5/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.2951 - accuracy: 0.6371 - val_loss: 2.3223 - val_accuracy: 0.6340\n",
      "Epoch 6/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.2209 - accuracy: 0.6511 - val_loss: 2.2987 - val_accuracy: 0.6378\n",
      "Epoch 7/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.1558 - accuracy: 0.6643 - val_loss: 2.2875 - val_accuracy: 0.6452\n",
      "Epoch 8/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.0885 - accuracy: 0.6768 - val_loss: 2.2508 - val_accuracy: 0.6533\n",
      "Epoch 9/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 2.0293 - accuracy: 0.6880 - val_loss: 2.2120 - val_accuracy: 0.6610\n",
      "Epoch 10/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.9818 - accuracy: 0.6968 - val_loss: 2.2060 - val_accuracy: 0.6638\n",
      "Epoch 11/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.9440 - accuracy: 0.7037 - val_loss: 2.2397 - val_accuracy: 0.6649\n",
      "Epoch 12/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.9112 - accuracy: 0.7094 - val_loss: 2.2299 - val_accuracy: 0.6686\n",
      "Epoch 13/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.8871 - accuracy: 0.7144 - val_loss: 2.2217 - val_accuracy: 0.6692\n",
      "Epoch 14/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.8639 - accuracy: 0.7184 - val_loss: 2.2545 - val_accuracy: 0.6670\n",
      "Epoch 15/30\n",
      "1302/1302 [==============================] - 28s 22ms/step - loss: 1.8434 - accuracy: 0.7223 - val_loss: 2.2256 - val_accuracy: 0.6737\n"
     ]
    }
   ],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"transformer_translate.keras\",\n",
    "        save_best_only=True\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_loss\",\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "    )\n",
    "]\n",
    "\n",
    "transformer.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"])\n",
    "translation_history = transformer.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " english (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " spanish (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " positional_embedding (Position  (None, None, 256)   3845120     ['english[0][0]']                \n",
      " alEmbedding)                                                                                     \n",
      "                                                                                                  \n",
      " positional_embedding_1 (Positi  (None, None, 256)   3845120     ['spanish[0][0]']                \n",
      " onalEmbedding)                                                                                   \n",
      "                                                                                                  \n",
      " transformer_encoder_1 (Transfo  (None, None, 256)   3155456     ['positional_embedding[0][0]']   \n",
      " rmerEncoder)                                                                                     \n",
      "                                                                                                  \n",
      " transformer_decoder (Transform  (None, None, 256)   5259520     ['positional_embedding_1[0][0]', \n",
      " erDecoder)                                                       'transformer_encoder_1[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, None, 256)    0           ['transformer_decoder[0][0]']    \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, None, 15000)  3855000     ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 19,960,216\n",
      "Trainable params: 19,960,216\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transformer.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Translating new sentences with our Transformer model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-\n",
      "Tom never did that here.\n",
      "[start] tom nunca hizo eso [end]\n",
      "-\n",
      "Tom has a problem with drug abuse.\n",
      "[start] tom tiene un problema con la [UNK] [end]\n",
      "-\n",
      "I knew you wanted me.\n",
      "[start] sab√≠a que me quer√≠as que yo me quer√≠a [end]\n",
      "-\n",
      "I don't want to leave.\n",
      "[start] no quiero salir [end]\n",
      "-\n",
      "I haven't heard from her since then.\n",
      "[start] no la he o√≠do desde entonces [end]\n",
      "-\n",
      "There's no more salt.\n",
      "[start] no queda m√°s sal [end]\n",
      "-\n",
      "His creditors are after him.\n",
      "[start] su profesor est√° [UNK] [end]\n",
      "-\n",
      "Why don't you want to listen to me?\n",
      "[start] por qu√© no quieres que me [UNK] [end]\n",
      "-\n",
      "I have to warn Tom.\n",
      "[start] tengo que [UNK] a tom [end]\n",
      "-\n",
      "I was watching TV at this time yesterday.\n",
      "[start] yo estaba viendo televisi√≥n a esta noche [end]\n",
      "-\n",
      "What do you say to a beer?\n",
      "[start] qu√© le digas a decir una cerveza [end]\n",
      "-\n",
      "You're not sick.\n",
      "[start] no est√°s enfermo [end]\n",
      "-\n",
      "Tom stuck his tongue out at Mary.\n",
      "[start] tom estaba comiendo en la lengua que mary [end]\n",
      "-\n",
      "They must be Americans.\n",
      "[start] ellos debe ser [UNK] [end]\n",
      "-\n",
      "Are you hiding from Tom?\n",
      "[start] est√°s escondiendo tom de tom [end]\n",
      "-\n",
      "We all knew it.\n",
      "[start] todos lo sabemos [end]\n",
      "-\n",
      "Can I offer you a ride?\n",
      "[start] puedo ti [UNK] una oferta [end]\n",
      "-\n",
      "This tie doesn't go with my suit.\n",
      "[start] esta tienda no queda con mi vestido [end]\n",
      "-\n",
      "Come and see.\n",
      "[start] ven a ver [end]\n",
      "-\n",
      "I know that you're lying.\n",
      "[start] s√© que est√°s mintiendo [end]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "spa_vocab = target_vectorization.get_vocabulary()\n",
    "spa_index_lookup = dict(zip(range(len(spa_vocab)), spa_vocab))\n",
    "max_decoded_sentence_length = 20\n",
    "\n",
    "def decode_sequence(input_sentence):\n",
    "    tokenized_input_sentence = source_vectorization([input_sentence])\n",
    "    decoded_sentence = \"[start]\"\n",
    "    for i in range(max_decoded_sentence_length):\n",
    "        tokenized_target_sentence = target_vectorization(\n",
    "            [decoded_sentence])[:, :-1]\n",
    "        predictions = transformer(\n",
    "            [tokenized_input_sentence, tokenized_target_sentence])\n",
    "        sampled_token_index = np.argmax(predictions[0, i, :])\n",
    "        sampled_token = spa_index_lookup[sampled_token_index]\n",
    "        decoded_sentence += \" \" + sampled_token\n",
    "        if sampled_token == \"[end]\":\n",
    "            break\n",
    "    return decoded_sentence\n",
    "\n",
    "test_eng_texts = [pair[0] for pair in test_pairs]\n",
    "for _ in range(20):\n",
    "    input_sentence = random.choice(test_eng_texts)\n",
    "    print(\"-\")\n",
    "    print(input_sentence)\n",
    "    print(decode_sequence(input_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"I am a very good student.\"\n",
    "spanish_sentence1 = decode_sequence(sentence1)\n",
    "sentence2a = \"Artificial intelligence is a great field\"\n",
    "spanish_sentence2a = decode_sequence(sentence2a)\n",
    "sentence2b = \"it has the potential to shape the future\"\n",
    "spanish_sentence2b = decode_sequence(sentence2b)\n",
    "sentence3a = \"Winston Churchill said\"\n",
    "spanish_sentence3a = decode_sequence(sentence3a)\n",
    "sentence3b = \"success is not final\"\n",
    "spanish_sentence3b = decode_sequence(sentence3b)\n",
    "sentence3c = \"failure is not fatal\"\n",
    "spanish_sentence3c = decode_sequence(sentence3c)\n",
    "sentence3d = \"it is the courage to continue that counts\"\n",
    "spanish_sentence3d = decode_sequence(sentence3d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[start] soy muy buena estudiante [end]\n",
      "[start] el [UNK] es una gran pa√≠s [end]\n",
      "[start] es el que el camino hasta el futuro [end]\n",
      "[start] [UNK] dijo que se [UNK] [end]\n",
      "[start] el √©xito no es perfecto [end]\n",
      "[start] no tiene √©xito no [UNK] [end]\n",
      "[start] es in√∫til que el valor de eso [UNK] [end]\n"
     ]
    }
   ],
   "source": [
    "print(spanish_sentence1)\n",
    "print(spanish_sentence2a)\n",
    "print(spanish_sentence2b)\n",
    "print(spanish_sentence3a)\n",
    "print(spanish_sentence3b)\n",
    "print(spanish_sentence3c)\n",
    "print(spanish_sentence3d)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Google Translate Back to English**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "I am a very good student\n",
    "the [UNK] is a great country\n",
    "Is the one the way to the future\n",
    "[UNK] said to be [UNK]\n",
    "success is not perfect\n",
    "not successful no [UNK]\n",
    "it is useless that the value of that [UNK]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-py38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
